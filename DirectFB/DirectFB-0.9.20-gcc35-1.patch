Submitted By: Uwe Düffert (lfs at uwe-dueffert dot de)
Date: 2004-05-13
Initial Package Version: 0.9.20
Origin: self-created, http://www.uwe-dueffert.de/lfs/ownpatches/DirectFB-0.9.20-gcc35-1.patch
Upstream Status: not reported
Description: fix gcc35 compilation issues
 
diff -Naur DirectFB-0.9.20.orig/src/core/surfaces.c DirectFB-0.9.20/src/core/surfaces.c
--- DirectFB-0.9.20.orig/src/core/surfaces.c	2003-10-17 16:11:34.000000000 +0000
+++ DirectFB-0.9.20/src/core/surfaces.c	2004-05-13 01:27:44.155398296 +0000
@@ -842,8 +842,8 @@
           __u8 buf_g[surface->width];
           
           /* Prepare one row. */
-          data8 = (__u8*)
-          data16 = (__u16*)
+          data8 = (__u8*)dfb_surface_data_offset( surface, data, pitch, 0, i );
+          data16 = (__u16*)dfb_surface_data_offset( surface, data, pitch, 0, i );
           data32 = dfb_surface_data_offset( surface, data, pitch, 0, i );
 
           switch (surface->format) {
diff -Naur DirectFB-0.9.20.orig/src/misc/memcpy.c DirectFB-0.9.20/src/misc/memcpy.c
--- DirectFB-0.9.20.orig/src/misc/memcpy.c	2003-08-15 11:33:06.000000000 +0000
+++ DirectFB-0.9.20/src/misc/memcpy.c	2004-05-13 01:27:45.149247208 +0000
@@ -196,6 +196,9 @@
      void *retval;
      size_t i;
      retval = to;
+     
+     const unsigned char * pfrom =from;
+     unsigned char * pto =to;
 
      if (len >= MMX1_MIN_LEN) {
           register unsigned long int delta;
@@ -226,16 +229,16 @@
                                     "movq %%mm5, 40(%1)\n"
                                     "movq %%mm6, 48(%1)\n"
                                     "movq %%mm7, 56(%1)\n"
-                                    :: "r" (from), "r" (to) : "memory");
-               ((const unsigned char *)from)+=64;
-               ((unsigned char *)to)+=64;
+                                    :: "r" (pfrom), "r" (pto) : "memory");
+               pfrom +=64;
+               pto +=64;
           }
           __asm__ __volatile__ ("emms":::"memory");
      }
      /*
       * Now do the tail of the block
       */
-     if (len) __memcpy(to, from, len);
+     if (len) __memcpy(pto, pfrom, len);
      return retval;
 }
 
@@ -248,6 +251,9 @@
      void *retval;
      size_t i;
      retval = to;
+     
+     const unsigned char * pfrom =from;
+     unsigned char * pto =to;
 
      /* PREFETCH has effect even for MOVSB instruction ;) */
      __asm__ __volatile__ (
@@ -288,9 +294,9 @@
                                     "movntq %%mm5, 40(%1)\n"
                                     "movntq %%mm6, 48(%1)\n"
                                     "movntq %%mm7, 56(%1)\n"
-                                    :: "r" (from), "r" (to) : "memory");
-               ((const unsigned char *)from)+=64;
-               ((unsigned char *)to)+=64;
+                                    :: "r" (pfrom), "r" (pto) : "memory");
+               pfrom+=64;
+               pto+=64;
           }
           /* since movntq is weakly-ordered, a "sfence"
           * is needed to become ordered again. */
@@ -300,7 +306,7 @@
      /*
       * Now do the tail of the block
       */
-     if (len) __memcpy(to, from, len);
+     if (len) __memcpy(pto, pfrom, len);
      return retval;
 }
 
@@ -313,6 +319,9 @@
      size_t i;
      retval = to;
 
+     const unsigned char * pfrom =from;
+     unsigned char * pto =to;
+     
      /* PREFETCH has effect even for MOVSB instruction ;) */
      __asm__ __volatile__ (
                           "   prefetchnta (%0)\n"
@@ -346,9 +355,9 @@
                                          "movntps %%xmm1, 16(%1)\n"
                                          "movntps %%xmm2, 32(%1)\n"
                                          "movntps %%xmm3, 48(%1)\n"
-                                         :: "r" (from), "r" (to) : "memory");
-                    ((const unsigned char *)from)+=64;
-                    ((unsigned char *)to)+=64;
+                                         :: "r" (pfrom), "r" (pto) : "memory");
+                    pfrom+=64;
+                    pto+=64;
                }
           else
                /*
@@ -368,9 +377,9 @@
                                          "movntps %%xmm1, 16(%1)\n"
                                          "movntps %%xmm2, 32(%1)\n"
                                          "movntps %%xmm3, 48(%1)\n"
-                                         :: "r" (from), "r" (to) : "memory");
-                    ((const unsigned char *)from)+=64;
-                    ((unsigned char *)to)+=64;
+                                         :: "r" (pfrom), "r" (pto) : "memory");
+                    pfrom+=64;
+                    pto+=64;
                }
           /* since movntq is weakly-ordered, a "sfence"
            * is needed to become ordered again. */
@@ -381,7 +390,7 @@
      /*
       * Now do the tail of the block
       */
-     if (len) __memcpy(to, from, len);
+     if (len) __memcpy(pto, pfrom, len);
      return retval;
 }
 
